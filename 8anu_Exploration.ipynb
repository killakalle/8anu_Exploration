{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.724Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "from IPython.display import Markdown as md\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import plot_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.730Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set for this project was downloaded from Kaggle at  \n",
    "[8anu climbing logbook](https://www.kaggle.com/dcohen21/8anu-climbing-logbook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to connect to the database provided and extract information into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.752Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "conn = sqlite3.connect('data/8anu.sqlite')\n",
    "\n",
    "# Read data into pandas\n",
    "sql = ('SELECT a.id, a.country AS crag_country, a.crag_id, a.crag, a.sector_id, a.sector, a.name AS route, '\n",
    "       'a.grade_id, g.fra_routes AS grade, a.year, a.date, a.method_id, m.shorthand AS method, a.notes, a.raw_notes, a.rating, '\n",
    "       'a.user_id, u.country AS user_country, u.city AS user_city, u.sex, u.height, u.weight, u.birth AS birthdate, u.started AS started_climbing '\n",
    "       'FROM ('\n",
    "           'SELECT * '\n",
    "           'FROM ascent '\n",
    "           'WHERE crag=\\'Frankenjura\\' AND climb_type=0'\n",
    "       ') AS a '\n",
    "       'LEFT OUTER JOIN grade AS g ON a.grade_id=g.id '\n",
    "       'LEFT OUTER JOIN method AS m ON a.method_id=m.id '\n",
    "       'LEFT OUTER JOIN user AS u ON a.user_id=u.id '\n",
    "       )\n",
    "df = pd.read_sql_query(sql, conn)\n",
    "\n",
    "# Close db connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create copy for later user\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two cells below extract data in CSV, as well as Excel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.766Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Export to .csv for submitting Project Proposal to Udacity\n",
    "#df.to_csv('data/8anu_franken.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.769Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Export to .xlsx\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "#writer = pd.ExcelWriter('data/8anu_franken.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "#df.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "#writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information about the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the columns and a few examples we extracted from our data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.790Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get a list of all columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.793Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.798Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| <p align='left'>`Column` | <p align='left'>Description | <p align='center'> Datatype | <p align='center'> Use | \n",
    "|:------|:------|:------:|:------:| \n",
    "| <p align='left'>`crag_country` | <p align='left'>3-letter country code of the country where the crag is located. | <p align='center'> categorical | <p align='center'> no | \n",
    "| <p align='left'>`crag_id` | <p align='left'>Unique id for identifying each crag. | <p align='center'> int | <p align='center'> no | \n",
    "| <p align='left'>`crag` | <p align='left'>Name of the crag | <p align='center'> text | <p align='center'> no | \n",
    "| <p align='left'>`sector_id` | <p align='left'>Unique id for identifying each sector. | <p align='center'> int | <p align='center'> yes | \n",
    "| <p align='left'>`sector` | <p align='left'>Name of the sector. A sector is a specific area within a crag. | <p align='center'> text | <p align='center'> yes | \n",
    "| <p align='left'>`route` | <p align='left'>Name of the route the climber has climbed. | <p align='center'> text | <p align='center'> yes | \n",
    "| <p align='left'>`grade_id` | <p align='left'>Unique id for identifying each climbing grade. | <p align='center'> int | <p align='center'> statistics | \n",
    "| <p align='left'>`grade` | <p align='left'>Climbing grade given to that route as per the French grading system | <p align='center'> categorical | <p align='center'> statistics | \n",
    "| <p align='left'>`year` | <p align='left'>Year the route was climbed | <p align='center'> int | <p align='center'> statistics | \n",
    "| <p align='left'>`date` | <p align='left'>Date the route was climbed. The date format is number of seconds since 1970-01-01. | <p align='center'> int | <p align='center'> statistics | \n",
    "| <p align='left'>`method_id` | <p align='left'>Unique id for identifying each type of ascent. | <p align='center'> int | <p align='center'> statistics | \n",
    "| <p align='left'>`method` | <p align='left'>The type of ascent the climber made on that route. | <p align='center'> categorical | <p align='center'> statistics | \n",
    "| <p align='left'>`notes` | <p align='left'>Additional information the climber provided for this climb, e.g. Soft graded, i.e. fairly easy climb for the given grade | <p align='center'> categorical | <p align='center'> statistics | \n",
    "| <p align='left'>`raw_notes` | <p align='left'>Encoding of different notes and combination of notes | <p align='center'> int | <p align='center'> statistics | \n",
    "| <p align='left'>`rating` | <p align='left'>Rating given to the climb by this climber. This is our target attribute. | <p align='center'> int | <p align='center'> target | \n",
    "| <p align='left'>`user_id` | <p align='left'>Unique id for this climber. | <p align='center'> int | <p align='center'> yes | \n",
    "| <p align='left'>`user_country` | <p align='left'>3-letter country code of the country where this climber is from. | <p align='center'> categorical | <p align='center'> statistics | \n",
    "| <p align='left'>`user_city` | <p align='left'>City where this climber is from | <p align='center'> text | <p align='center'> statistics | \n",
    "| <p align='left'>`sex` | <p align='left'>The climber's sex. 0 indicates male, 1 indicates female. | <p align='center'> int | <p align='center'> statistics | \n",
    "| <p align='left'>`height` | <p align='left'>The climber's height in cm | <p align='center'> int | <p align='center'> statistics | \n",
    "| <p align='left'>`weight` | <p align='left'>The climber's weight in kg | <p align='center'> int | <p align='center'> statistics | \n",
    "| <p align='left'>`birthdate` | <p align='left'>The climber's date of birth | <p align='center'> date | <p align='center'> statistics | \n",
    "| <p align='left'>`started_climbing` | <p align='left'>The year the climber started climbing. | <p align='center'> int | <p align='center'> statistics | ![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above the column `Use` indicated how we plan to use the given column.\n",
    "- `target` - this is a target attribute.\n",
    "- `yes` - this column will be used during exploration and analysis.\n",
    "- `no` - not planned to use that column during analysis and exploration.\n",
    "- `statistics` - this column will not be used for analysis but may be interesting later on to do user statistics etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is our data set? How many climbs contain a rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.841Z"
    }
   },
   "outputs": [],
   "source": [
    "records_count = df.shape[0]\n",
    "ratings_count = df[ df['rating'] == 0].shape[0]\n",
    "\n",
    "\n",
    "f'There are {records_count:,} data entries in our dataset.'\n",
    "f'{ratings_count:,} out of these contain a rating. That is approx. {ratings_count / records_count * 100:.2f}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not use all the columns from the data set. Let's drop unnecessary columns for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.852Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['crag_country',\n",
    "                      'crag_id',\n",
    "                      'crag',\n",
    "                      'grade_id',\n",
    "                      'grade',\n",
    "                      'year',\n",
    "                      'date',\n",
    "                      'method_id',\n",
    "                      'method',\n",
    "                      'notes',\n",
    "                      'raw_notes',\n",
    "                      'user_country',\n",
    "                      'user_city',\n",
    "                      'sex',\n",
    "                      'height',\n",
    "                      'weight',\n",
    "                      'birthdate',\n",
    "                      'started_climbing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "Let us take a look if we have **missing values** or **zero values**.\n",
    "\n",
    "Number of missing values per column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.867Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T22:29:42.784818Z",
     "start_time": "2018-11-15T22:29:42.780805Z"
    }
   },
   "source": [
    "This means there are no entries missing in the columns that we look at.\n",
    "\n",
    "Number of zero values per column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.877Z"
    }
   },
   "outputs": [],
   "source": [
    "(df == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T21:43:21.925488Z",
     "start_time": "2018-12-08T21:43:21.921630Z"
    }
   },
   "source": [
    "However, there a quite a significant amount of sector_IDs missing and also a lot of ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive calculation on the number of unique sectors and routes within these sectors. Submitted by a number of distinct users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.902Z"
    }
   },
   "outputs": [],
   "source": [
    "df[['sector_id', 'route', 'user_id']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we call the above estimate _naive_? \n",
    "\n",
    "According to [climb-europe.com](http://www.climb-europe.com/RockClimbingGermany/RockClimbingFrankenjura.html) _\"there are approximately 1,000 crags spread out in a beautiful forest terrain.\"_ (Note that _crags_ in the above quote is the same as _sectors_ in our dataset.) This seems fine since in our dataset there are 351 different sectors noted.\n",
    "\n",
    "However, let's look closer here. What are the records where `sector_id` is 0?  \n",
    "We take a look at a number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.913Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['sector_id'] == 0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what we can see is, that `sector_id == 0` actually does not belong to a proper sector, but rather denotes that sector is not known in this case. Later we'll have to remove those entries.\n",
    "\n",
    "In the article it continues to claim that _Frankenjura boasts in excess of 10,000 routes._ Now this is where we should get a little suspicious. In only 350 sectors our dataset apparently contains already more than 12,000 routes - which is well above the 10,000 mentioned in the article.\n",
    "\n",
    "Lets dig deeper here. Maybe there are a number of duplicates in the registered routes. Let's see if an example can confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.923Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['route'].str.startswith('knack')].drop_duplicates(subset=['route'])['route']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:50:48.268729Z",
     "start_time": "2018-12-11T19:50:48.264205Z"
    }
   },
   "source": [
    "We will have to consolidate those duplicates during Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "Lets visualize the **Missing** and **Zero values** per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:05.953Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_helper.missing_values_overview(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data set `0` is in indicator for missing values, except for `sex` where `0` indicates `male` (and `1` for `female`).\n",
    "\n",
    "From the graph above we can conclude that we have missing data in `sector_id` and `rating`.\n",
    "\n",
    "Since `sector_id` and `rating` are important for our analysis, we have to consider what to do about those missing values during Data Preparation later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of our target variable `rating`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the unique values of our target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.036Z"
    }
   },
   "outputs": [],
   "source": [
    "df_y = df['rating']\n",
    "df_y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how is their distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.051Z"
    }
   },
   "outputs": [],
   "source": [
    "total = df_y.count()\n",
    "\n",
    "ax = df_y.value_counts().sort_index().plot(\n",
    "    kind='bar', title='ratings distribution')\n",
    "_ = ax.set_ylabel('logged ascents')\n",
    "_ = ax.set_xlabel('given rating')\n",
    "\n",
    "for i in ax.patches:\n",
    "    _ = ax.text(i.get_x()-.03, i.get_height()+.5, \\\n",
    "            str(round((i.get_height()/total)*100, 1))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution of the target variable `rating`, we can see that there are four distinct values. With 52.7% of ratings equal to 0, only about half of the ascents have been rated.\n",
    "\n",
    "In the climbing community it is commonplace to rate only good climbs by marking them with a star. Thus, the values `1`, `2` or `3` correspond to one, two or three stars. Where one star is a good route and three stars is an exceptional good climb.\n",
    "\n",
    "Hence the value `0`, or zero stars, denotes that a climb was either not rated or was not worth a star according to that used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.069Z"
    }
   },
   "outputs": [],
   "source": [
    "df_y[df_y != 0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T23:40:18.226175Z",
     "start_time": "2018-11-15T23:40:18.222324Z"
    }
   },
   "source": [
    "Out of those climbs, that were rated, the average is 2.14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of users that rated at least one climb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.100Z"
    }
   },
   "outputs": [],
   "source": [
    "(df.groupby('user_id')['rating'].sum() == 0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T00:02:23.741029Z",
     "start_time": "2018-11-16T00:02:23.736576Z"
    }
   },
   "source": [
    "This means that approx. 2/3 of users have rated at least one item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many ratings are there per user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.183Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings_per_user = df.groupby('user_id')['rating'].apply(lambda x: x[x != 0].count())\n",
    "ax = ratings_per_user.sort_values().plot(\n",
    "    kind='line', title='No. of ratings per user (sorted by no. of ratings)', use_index=False)\n",
    "_ = ax.set_ylabel('no. of ratings')\n",
    "_ = ax.set_xlabel('user id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot we can see that there must be one or several outliers with a large number of ratings (around 1600). Let's apply the logarithm on the y-axis to get a better picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.196Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = ratings_per_user.sort_values().plot(\n",
    "    kind='line', title='No. of ratings per user (logscale)', use_index=False, logy=True)\n",
    "_ = ax.set_ylabel('no. of ratings')\n",
    "_ = ax.set_xlabel('user id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-17T13:04:14.897030Z",
     "start_time": "2018-11-17T13:04:14.893184Z"
    }
   },
   "source": [
    "Now, this has more information. We can see that approx. 30% of users gave no rating at all. And more than 90% of users gave less than 200 ratings.\n",
    "\n",
    "Let's look at the percentiles information in detail to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.206Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings_per_user.describe(percentiles=[.25, 0.33, .50, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms and Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:09:20.210374Z",
     "start_time": "2018-12-20T06:09:20.164945Z"
    }
   },
   "source": [
    "As a benchmark we'll use a __random recommender__, i.e. for a given user, any route will be given a random rating from 1, 2 or 3 stars. This will be our quantitative measurement to compare against.  \n",
    "For a __qualitative benchmark__, we'll compare results to the recommendations by climbing magazine _klettern.de_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove records from dataset where `sector_id == 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.255Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['sector_id'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate route names, remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T15:37:36.277416Z",
     "start_time": "2018-11-18T15:37:36.273212Z"
    }
   },
   "source": [
    "Since our data set does not provide a unique id for routes, we can only go by the name to identify a route. Unfortunately, there are many versions of route names as well as spelling mistakes. In order to arrive at a unique list of routes, we need to do some cleaning up.  \n",
    "\n",
    "The following example illustrates that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.275Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['route'].str.startswith('Adr')].drop_duplicates(subset=['route'])['route']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by converting all route names to lowercase and removing special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.286Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def string_cleaning(df, columns):\n",
    "    '''Remove special characters and convert to lowercase. Apply to all columns as specified'''\n",
    "\n",
    "    df[columns] = df[columns].applymap(lambda s: s.lower())\n",
    "\n",
    "    # Need to use Series because regular replace() cannot handle RegEx\n",
    "    for c in columns:\n",
    "        df[c] = df[c].str.replace('[^A-Za-z\\s]+', '') # TODO keep numbers??\n",
    "        \n",
    "        # Remove rows with empty values as they are unusable\n",
    "        df = df[df[c] != '']\n",
    "\n",
    "    return df\n",
    "\n",
    "df = string_cleaning(df, ['route'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a couple of functions that will help us to clean up duplicate route names within sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.295Z"
    },
    "code_folding": [
     3,
     22
    ]
   },
   "outputs": [],
   "source": [
    "# http://www.coli.uni-saarland.de/courses/LT1/2011/slides/Python-Levenshtein.html\n",
    "from Levenshtein import jaro_winkler\n",
    "\n",
    "def create_jaro_winkler(keys, prefix_weight=None):\n",
    "    '''Calculates Jaro-Winkler-Distance among all items of `keys` and returns calculation results as a matrix'''\n",
    "\n",
    "    # TODO  is there a more pythonic way of calculating this matrix?\n",
    "    \n",
    "    jaro_winkler_matrix = np.ones((len(keys), len(keys)))\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(keys) - 1:\n",
    "        j = 0\n",
    "        while j <= len(keys) - 1:\n",
    "            if i != j:\n",
    "                jaro_winkler_matrix[i][j] = jaro_winkler(\n",
    "                    keys[i], keys[j]) if prefix_weight is None else jaro_winkler(keys[i], keys[j], prefix_weight)\n",
    "            j += 1\n",
    "        i += 1\n",
    "\n",
    "    return jaro_winkler_matrix\n",
    "\n",
    "def remove_overlap(d):\n",
    "    '''Resolve 'paths' within the dictionary, e.g. \n",
    "     { A : B, B : C }  ->  { A : C, B : C }\n",
    "     Returns cleaned dictionary'''\n",
    "\n",
    "    set_keys = set(d.keys())\n",
    "    set_values = set(d.values())\n",
    "    set_intersect = set_keys.intersection(set_values)\n",
    "\n",
    "    for v in set_intersect:\n",
    "        new_target = d[v]\n",
    "\n",
    "        filtered_dict = {key: new_target for (\n",
    "            key, value) in d.items() if value == v}\n",
    "        filtered_dict\n",
    "\n",
    "        for i, j in d.items():\n",
    "            if i in filtered_dict.keys():\n",
    "                d[i] = filtered_dict[i]\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.299Z"
    },
    "code_folding": [
     0,
     6,
     50
    ]
   },
   "outputs": [],
   "source": [
    "def get_routes_per_sector(df, sector_id):\n",
    "    '''Returns a series with route names as labels and count of route name occurrences as values'''\n",
    "\n",
    "    df_one_sector = df[df['sector_id'] == sector_id]\n",
    "    return df_one_sector['route'].value_counts()\n",
    "\n",
    "def clean_route_names_sector(df, sector_id, threshold=0.9, prefix_weight=1/100, debug=False):\n",
    "    '''Replaces route name within given `sector_id` with the most similar matching name that has the most occurrences.'''\n",
    "\n",
    "    routes_per_sector = get_routes_per_sector(df, sector_id)\n",
    "    keys = routes_per_sector.keys()\n",
    "    values = routes_per_sector.values\n",
    "\n",
    "    # Create Jaro-Winkler-Matrix and fill diagonal with zeros, \n",
    "    # otherwise max value will always be 1.0 (as diagonal is always 1.0)\n",
    "    jaro_winkler_matrix = create_jaro_winkler(keys, prefix_weight)\n",
    "    np.fill_diagonal(jaro_winkler_matrix, 0)\n",
    "\n",
    "    # empty nested dictionary, for replacements of similar route names\n",
    "    replacements = {'route': {}}\n",
    "\n",
    "    # find max count of values above threshold\n",
    "    indices_above_threshold = np.transpose(\n",
    "        np.nonzero(jaro_winkler_matrix >= threshold))\n",
    "\n",
    "    first_values = [t[0] for t in indices_above_threshold]\n",
    "    unique_first_values = np.unique(first_values)\n",
    "\n",
    "    for u in unique_first_values:\n",
    "        tuples_list = [t for t in indices_above_threshold if t[0] == u]\n",
    "        counts_list = [values[t2[1]] for t2 in tuples_list]\n",
    "        val_max = max(counts_list)\n",
    "        index_max = counts_list.index(max(counts_list))\n",
    "        keys[tuples_list[index_max][1]]\n",
    "\n",
    "        if values[u] < values[tuples_list[index_max][1]]:\n",
    "            replacements['route'][keys[u]] = keys[tuples_list[index_max][1]]\n",
    "            if debug:\n",
    "                print(\n",
    "                    f'Replacement: {keys[u]}({values[u]}) : {keys[tuples_list[index_max][1]]}({values[tuples_list[index_max][1]]}) ')        \n",
    "\n",
    "    # Resolve overlaps in replacements\n",
    "    replacements['route'] = remove_overlap(replacements['route'])\n",
    "        \n",
    "    # Replace all found similar route names\n",
    "    df.loc[df['sector_id'] == sector_id] = df.replace(\n",
    "        to_replace=replacements)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_route_names(df):\n",
    "    '''Cleans up duplicate route names within sectors.'''\n",
    "    \n",
    "    for sid in df['sector_id'].unique():\n",
    "        df = clean_route_names_sector(df, sid)\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.301Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "df = clean_route_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.305Z"
    }
   },
   "outputs": [],
   "source": [
    "# jaro_winkler('adrschpach weg', 'adrspach weg', 1/100)\n",
    "df[df['route'].str.startswith('adr')].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of unique routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all the individual routes. We also keep `sector_id` here, because there can be routes with the same name that lie in different sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.323Z"
    }
   },
   "outputs": [],
   "source": [
    "df_routes = df[['sector_id', 'route']].drop_duplicates(['sector_id', 'route'])\n",
    "a = df_routes.shape[0]\n",
    "md(f'So, our new count for routes is **{a}**, which is a lot less than what our naive count was.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T00:50:26.805548Z",
     "start_time": "2018-11-20T00:50:26.801700Z"
    }
   },
   "source": [
    "Reset the index of our consolidated list of routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.335Z"
    }
   },
   "outputs": [],
   "source": [
    "df_routes.index.name = 'route_id'\n",
    "df_routes.reset_index(inplace=True)\n",
    "df_routes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.346Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users = df['user_id'].drop_duplicates()\n",
    "df_users.reset_index(inplace=True, drop=True)\n",
    "df_users.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-20T00:54:30.111003Z",
     "start_time": "2018-11-20T00:54:30.107092Z"
    }
   },
   "source": [
    "### Get list of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.361Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings = pd.merge(df_routes, df, on=['sector_id', 'route'])[['route_id', 'sector', 'route', 'user_id', 'rating']]\n",
    "df_ratings['sector_route'] = df_ratings['sector'] + '_' + df_ratings['route']\n",
    "df_ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter ratings, only include non-NaN values\n",
    "df_ratings = df_ratings[df_ratings['rating'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement random model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.382Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "df_ratings_random = df_ratings\n",
    "df_ratings_random['rating_random'] = df_ratings_random.apply(lambda row: randint(1, 3), axis=1)\n",
    "\n",
    "df_ratings_random.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.385Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "y_actual = df_ratings_random['rating']\n",
    "y_predict = df_ratings_random['rating_random']\n",
    "\n",
    "rms = sqrt(mean_squared_error(y_actual, y_predict))\n",
    "f'The RMSE for our random model is {rms:.4f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:35:49.917899Z",
     "start_time": "2018-12-20T06:35:49.913832Z"
    }
   },
   "source": [
    "Tbe benchmark of our random model is `RMSE = 1.1321`, which is the value we want to _beat_ with our recommender model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement K-Means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.410Z"
    }
   },
   "outputs": [],
   "source": [
    "user_route_ratings = pd.pivot_table(df_ratings, index='user_id', columns= 'sector_route', values='rating')\n",
    "\n",
    "print('dataset dimensions: ', user_route_ratings.shape, '\\n\\nSubset example:')\n",
    "user_route_ratings.iloc[:6, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.413Z"
    }
   },
   "outputs": [],
   "source": [
    "# user_id = 39\n",
    "# # user_id = 35939\n",
    "# X_test[X_test['user_id'] == user_id]\n",
    "# # user_route_ratings.loc[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.418Z"
    },
    "code_folding": [
     0,
     15,
     30
    ]
   },
   "outputs": [],
   "source": [
    "def get_most_rated_routes(user_route_ratings, max_number_of_routes):\n",
    "    # 1- Count\n",
    "    user_route_ratings = user_route_ratings.append(\n",
    "        user_route_ratings.count(), ignore_index=True)\n",
    "    # 2- sort\n",
    "    user_route_ratings_sorted = user_route_ratings.sort_values(\n",
    "        len(user_route_ratings)-1, axis=1, ascending=False)\n",
    "    user_route_ratings_sorted = user_route_ratings_sorted.drop(\n",
    "        user_route_ratings_sorted.tail(1).index)\n",
    "    # 3- slice\n",
    "    most_rated_routes = user_route_ratings_sorted.iloc[:,\n",
    "                                                       :max_number_of_routes]\n",
    "    return most_rated_routes\n",
    "\n",
    "\n",
    "def get_users_who_rate_the_most(most_rated_routes, max_number_of_routes):\n",
    "    # Get most voting users\n",
    "    # 1- Count\n",
    "    most_rated_routes['counts'] = pd.Series(most_rated_routes.count(axis=1))\n",
    "    # 2- Sort\n",
    "    most_rated_routes_users = most_rated_routes.sort_values(\n",
    "        'counts', ascending=False)\n",
    "    # 3- Slice\n",
    "    most_rated_routes_users_selection = most_rated_routes_users.iloc[:max_number_of_routes, :]\n",
    "    most_rated_routes_users_selection = most_rated_routes_users_selection.drop([\n",
    "                                                                               'counts'], axis=1)\n",
    "\n",
    "    return most_rated_routes_users_selection\n",
    "\n",
    "\n",
    "def sort_by_rating_density(user_route_ratings, n_routes, n_users):\n",
    "    most_rated_routes = get_most_rated_routes(user_route_ratings, n_routes)\n",
    "    most_rated_routes = get_users_who_rate_the_most(most_rated_routes, n_users)\n",
    "    return most_rated_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.422Z"
    }
   },
   "outputs": [],
   "source": [
    "n_routes = 30\n",
    "n_users = 18\n",
    "most_rated_routes_users_selection = sort_by_rating_density(user_route_ratings, n_routes, n_users)\n",
    "\n",
    "print('dataset dimensions: ', most_rated_routes_users_selection.shape)\n",
    "most_rated_routes_users_selection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above table `sector_route` is label of column names, not the label of the first column. cp. to first table in Implementation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.432Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def draw_routes_heatmap(most_rated_routes_users_selection, axis_labels=True):\n",
    "\n",
    "    # Reverse to match the order of the printed dataframe\n",
    "    #most_rated_routes_users_selection = most_rated_routes_users_selection.iloc[::-1]\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Draw heatmap\n",
    "    heatmap = ax.imshow(most_rated_routes_users_selection,\n",
    "                        interpolation='nearest', vmin=0, vmax=3, aspect='auto')\n",
    "\n",
    "    if axis_labels:\n",
    "        ax.set_yticks(\n",
    "            np.arange(most_rated_routes_users_selection.shape[0]), minor=False)\n",
    "        ax.set_xticks(\n",
    "            np.arange(most_rated_routes_users_selection.shape[1]), minor=False)\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.tick_top()\n",
    "        labels = most_rated_routes_users_selection.columns.str[:40]\n",
    "        ax.set_xticklabels(labels, minor=False)\n",
    "        ax.set_yticklabels(\n",
    "            most_rated_routes_users_selection.index, minor=False)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "    else:\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax.grid(False)\n",
    "    ax.set_ylabel('User id')\n",
    "\n",
    "    # Separate heatmap from color bar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "    # Color bar\n",
    "    cbar = fig.colorbar(heatmap, ticks=[3, 2, 1, 0], cax=cax)\n",
    "    cbar.ax.set_yticklabels(['3 stars', '2 stars', '1 stars', '0 stars'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.434Z"
    }
   },
   "outputs": [],
   "source": [
    "draw_routes_heatmap(most_rated_routes_users_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.437Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse_ratings = csr_matrix(pd.SparseDataFrame(user_route_ratings).to_coo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.449Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def clustering_errors(k, data):\n",
    "    kmeans = KMeans(n_clusters=k).fit(data)\n",
    "    predictions = kmeans.predict(data)\n",
    "    silhouette_avg = silhouette_score(data, predictions)\n",
    "    return silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose the range of k values to test.\n",
    "# We added a stride of 5 to improve performance. We don't need to calculate the error for every k value\n",
    "# possible_k_values = range(2, len(X)-1, 5)\n",
    "possible_k_values = range(2, 20, 2)\n",
    "\n",
    "# Calculate error values for all k values we're interested in\n",
    "errors_per_k = [clustering_errors(k, sparse_ratings) for k in possible_k_values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.455Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot each value of K vs. the silhouette score at that value\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "_ = ax.set_xlabel('K - number of clusters')\n",
    "_ = ax.set_ylabel('Silhouette Score (higher is better)')\n",
    "_ = ax.plot(possible_k_values, errors_per_k)\n",
    "\n",
    "# Ticks and grid\n",
    "xticks = np.arange(min(possible_k_values), max(possible_k_values)+1, 5.0)\n",
    "_ = ax.set_xticks(xticks, minor=False)\n",
    "_ = ax.set_xticks(xticks, minor=True)\n",
    "_ = ax.xaxis.grid(True, which='both')\n",
    "yticks = np.arange(round(min(errors_per_k), 2), max(errors_per_k), .05)\n",
    "_ = ax.set_yticks(yticks, minor=False)\n",
    "_ = ax.set_yticks(yticks, minor=True)\n",
    "_ = ax.yaxis.grid(True, which='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict user clusters using KMeans\n",
    "predictions = KMeans(n_clusters=2, algorithm='full').fit_predict(sparse_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.491Z"
    }
   },
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.493Z"
    }
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.496Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def draw_route_clusters(clustered, max_users, max_routes):\n",
    "    c = 1\n",
    "    for cluster_id in clustered.group.unique():\n",
    "        # To improve visibility, we're showing at most max_users users and max_routes routes per cluster.\n",
    "        # You can change these values to see more users & routes per cluster\n",
    "        d = clustered[clustered.group == cluster_id].drop(\n",
    "            ['user_id', 'group'], axis=1)\n",
    "        n_users_in_cluster = d.shape[0]\n",
    "\n",
    "        d = sort_by_rating_density(d, max_routes, max_users)\n",
    "\n",
    "#         d = d.reindex_axis(d.mean().sort_values(ascending=False).index, axis=1)\n",
    "#         d = d.reindex_axis(d.count(axis=1).sort_values(ascending=False).index)\n",
    "        d = d.reindex(d.mean().sort_values(ascending=False).index, axis=1)\n",
    "        d = d.reindex(d.count(axis=1).sort_values(ascending=False).index)\n",
    "        d = d.iloc[:max_users, :max_routes]\n",
    "        n_users_in_plot = d.shape[0]\n",
    "\n",
    "        # We're only selecting to show clusters that have more than 9 users, otherwise, they're less interesting\n",
    "        if len(d) > 9:\n",
    "            print('cluster # {}'.format(cluster_id))\n",
    "            print('# of users in cluster: {}.'.format(n_users_in_cluster),\n",
    "                  '# of users in plot: {}'.format(n_users_in_plot))\n",
    "            fig = plt.figure(figsize=(15, 4))\n",
    "            ax = plt.gca()\n",
    "\n",
    "            ax.invert_yaxis()\n",
    "            ax.xaxis.tick_top()\n",
    "            labels = d.columns.str[:40]\n",
    "\n",
    "            ax.set_yticks(np.arange(d.shape[0]), minor=False)\n",
    "            ax.set_xticks(np.arange(d.shape[1]), minor=False)\n",
    "\n",
    "            ax.set_xticklabels(labels, minor=False)\n",
    "\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            # Heatmap\n",
    "            heatmap = plt.imshow(d, vmin=1, vmax=3, aspect='auto')\n",
    "\n",
    "            ax.set_xlabel('routes')\n",
    "            ax.set_ylabel('User id')\n",
    "\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "            # Color bar\n",
    "            cbar = fig.colorbar(heatmap, ticks=[3, 2, 1], cax=cax)\n",
    "            cbar.ax.set_yticklabels(\n",
    "                ['3 stars', '2 stars', '1 stars'])\n",
    "\n",
    "            plt.setp(ax.get_xticklabels(), rotation=90, fontsize=9)\n",
    "            plt.tick_params(axis='both', which='both', bottom='off',\n",
    "                            top='off', left='off', labelbottom='off', labelleft='off')\n",
    "            # print('cluster # {} \\n(Showing at most {} users and {} routes)'.format(cluster_id, max_users, max_routes))\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.499Z"
    }
   },
   "outputs": [],
   "source": [
    "max_users = 70\n",
    "max_routes = 50\n",
    "\n",
    "# is this line messing up my user_id?\n",
    "clustered = pd.concat([user_route_ratings.reset_index(),\n",
    "                       pd.DataFrame({'group': predictions})], axis=1)\n",
    "clustered = clustered.set_index('user_id')\n",
    "clustered['user_id'] = clustered.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.502Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get a random cluster number with cluster size >= threshold\n",
    "threshold = 1\n",
    "group_counts = clustered['group'].value_counts()\n",
    "group_counts = group_counts[group_counts >= threshold]\n",
    "group_counts\n",
    "random_cluster_number = group_counts.sample(1).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.504Z"
    }
   },
   "outputs": [],
   "source": [
    "draw_route_clusters(clustered, max_users, max_routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prediction\n",
    "Let's pick a cluster and a specific user and see what useful things this clustering will allow us to do.\n",
    "\n",
    "Let's first pick a cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.515Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_cluster(clustered, cluster_number):\n",
    "    \n",
    "#     cluster = clustered[clustered.group == cluster_number].drop(['user_id', 'group'], axis=1)\n",
    "    cluster = clustered[clustered.group == cluster_number].drop(['group'], axis=1)\n",
    "    cluster = cluster.set_index('user_id')\n",
    "    cluster = cluster.rename_axis('user_id')\n",
    "    \n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.517Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Pick a cluster ID from the clusters above\n",
    "cluster_number = random_cluster_number\n",
    "\n",
    "# Let's filter to only see the region of the dataset with the most number of values \n",
    "n_users = 75\n",
    "n_routes = 300\n",
    "cluster = get_cluster(clustered, cluster_number)\n",
    "\n",
    "cluster = sort_by_rating_density(cluster, n_routes, n_users)\n",
    "draw_routes_heatmap(cluster, axis_labels=False)\n",
    "\n",
    "# set cluster back to original (because sort_by_rating_density() modifies cluster)\n",
    "cluster = get_cluster(clustered, cluster_number) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.520Z"
    }
   },
   "outputs": [],
   "source": [
    "route_name = 'Wolfsberger Grotte_panda'\n",
    "\n",
    "cluster[route_name].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.522Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cluster_membership(clustered, user_id):\n",
    "    '''given a clustered dataframe, returns the cluster number that user_id is a member of'''\n",
    "    \n",
    "    return clustered[clustered['user_id'] == user_id]['group'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.525Z"
    }
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "\n",
    "Weighted Rating (WR) = $(\\frac{v}{v + m} \\cdot R) + (\\frac{m}{v + m} \\cdot C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T22:53:41.247684Z",
     "start_time": "2018-11-24T22:53:41.242855Z"
    }
   },
   "source": [
    "where\n",
    "- *v* is the number of ratings for that route\n",
    "- *m* is the minimum ratings required to be listed in the chart\n",
    "- *R* is the average rating of the route\n",
    "- *C* is the mean vote across the whole report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.533Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cluster_avg_count(cluster):\n",
    "    '''Given a cluster, calculate each route's avg rating and count of ratings. '''\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['sector_route'] = cluster.columns\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        rating_average = cluster[row['sector_route']].mean()\n",
    "        rating_count = cluster[row['sector_route']].count()\n",
    "        df.at[i,'rating_average'] = rating_average\n",
    "        df.at[i,'rating_count'] = rating_count\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.536Z"
    },
    "code_folding": [
     0,
     27
    ]
   },
   "outputs": [],
   "source": [
    "def top_n_routes_cluster(cluster, n=0):\n",
    "    '''Calculate weighted rating of all routes. Return top-n routes. If n==0, return all routes'''\n",
    "\n",
    "    percentile = 0.85\n",
    "\n",
    "    # get count and mean of ratings per route for this cluster\n",
    "    df_counts_average = cluster_avg_count(cluster)\n",
    "\n",
    "    C = df_counts_average['rating_average'].mean()\n",
    "    m = df_counts_average['rating_count'].quantile(percentile)\n",
    "\n",
    "    # Filter for routes that have ratings above threshold m\n",
    "    qualified = df_counts_average[(df_counts_average['rating_count'] >= m) & (\n",
    "        df_counts_average['rating_count'].notnull()) & (df_counts_average['rating_average'].notnull())]\n",
    "\n",
    "    # calculate weighted rating for each route\n",
    "    col_wr = qualified.apply(lambda x: (x['rating_count']/(x['rating_count']+m)\n",
    "                                                 * x['rating_average']) + (m/(m+x['rating_count']) * C), axis=1)\n",
    "    qualified = qualified.assign(wr=col_wr.values)\n",
    "    \n",
    "    # Sort by rating\n",
    "    qualified = qualified.sort_values(\n",
    "        'wr', ascending=False) if n == 0 else qualified.sort_values('wr', ascending=False).head(n)\n",
    "\n",
    "    # Return the top n routes\n",
    "    return qualified\n",
    "\n",
    "def top_n_routes_user(clustered, user_id, n):\n",
    "    '''Return top n routes of a user'''\n",
    "\n",
    "    # get cluster number\n",
    "    cluster_number = cluster_membership(clustered, user_id)\n",
    "\n",
    "    # retrieve cluster by cluster number\n",
    "    cluster = get_cluster(clustered, cluster_number)\n",
    "\n",
    "    # retrieve top routes by cluster\n",
    "    df_top_routes_cluster = top_n_routes_cluster(cluster)\n",
    "\n",
    "    # subtract user's already climbed and rated routes from result\n",
    "    df_top_routes_cluster_without_user = df_top_routes_cluster.drop(\n",
    "        df_top_routes_cluster[df_top_routes_cluster['sector_route'].isin(cluster.loc[user_id].dropna().index)].index)\n",
    "\n",
    "    return df_top_routes_cluster_without_user.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.539Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id = 32\n",
    "clustered[clustered['user_id'] == user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.545Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id = 32\n",
    "\n",
    "cluster_number = cluster_membership(clustered, user_id)\n",
    "f'cluster_number: {cluster_number}'\n",
    "cluster = get_cluster(clustered, cluster_number)\n",
    "cluster\n",
    "\n",
    "top_n = top_n_routes_cluster(cluster)\n",
    "top_n.shape\n",
    "\n",
    "top_n_without_user = top_n.drop(\n",
    "    top_n[top_n['sector_route'].isin(cluster.loc[user_id].dropna().index)].index)\n",
    "\n",
    "top_n_without_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.549Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster = get_cluster(clustered, random_cluster_number)\n",
    "cluster.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative result check\n",
    "\n",
    "For a qualitative result check, let's look at the top 20 recommended routes within a cluster and count how many of the routes show up in the Top 100 list of climbing magazine _klettern_. The list is available on the [klettern.de](https://www.klettern.de/sixcms/media.php/8/Top100-Kletterrouten_Frankenjura.pdf) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.559Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "f'Top 20 Cluster'\n",
    "top_n_routes_cluster(cluster, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find 9 out of 20 recommended routes also in the Top 100 list. So, our recommendations seem to be alright."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T21:40:34.406831Z",
     "start_time": "2018-12-09T21:40:34.400167Z"
    }
   },
   "source": [
    "<img src=\"images/qualitative_benchmark.png\" alt=\"Qualitative Benchmark\" width=\"500\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The suggested routes are all in the upper experienced to expert level. Which is no surprise, as we have seen earlier, that the majority of climbed routes is from that range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.581Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "users = [32, 493, 35939, 63837]\n",
    "for u in users:\n",
    "    f'user_id: {u} is member of cluster number: {cluster_membership(clustered, u)}'\n",
    "    top_n_routes_user(clustered, u, 5)\n",
    "    f''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.585Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def predict_user_rating(user_id, sector_route):\n",
    "    '''Predict what a user's rating for a particular route would be.'''\n",
    "    \n",
    "    # determine cluster membership and get cluster\n",
    "    cluster_number = cluster_membership(clustered, user_id)\n",
    "    cluster = get_cluster(clustered, cluster_number)\n",
    "    \n",
    "    # get ratings<->routes for cluster\n",
    "    rated_routes = top_n_routes_cluster(cluster)\n",
    "    \n",
    "    # get rating of route\n",
    "    rating = rated_routes[rated_routes['sector_route'] == sector_route]['wr']\n",
    "    \n",
    "    return rating.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.588Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_user_rating(32, 'Eldorado_ekel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-20T06:15:23.268Z"
    }
   },
   "source": [
    "### Alternative Implementation -  SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying Surprise package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.603Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import SVD, SVDpp\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "reader = Reader(rating_scale=(1, 3))\n",
    "\n",
    "data = Dataset.load_from_df(df_ratings[['user_id', 'sector_route', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.605Z"
    }
   },
   "outputs": [],
   "source": [
    "svd = SVD()\n",
    "_ = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.607Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the example provided on the website of the [surprise package](https://surprise.readthedocs.io/en/stable/FAQ.html), we can implement a top n recommender like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.615Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Then predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.618Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.disable()  # following recommendation of https://bugs.python.org/issue2607\n",
    "\n",
    "# Print the recommended routes for each user\n",
    "counter = 0\n",
    "for uid, user_ratings in top_n.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])\n",
    "    print()\n",
    "    counter += 1\n",
    "    if counter == 3:\n",
    "        break\n",
    "        \n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.621Z"
    }
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "gc.disable()  # following recommendation of https://bugs.python.org/issue2607\n",
    "top_n[5512]\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning , GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a grid search on a number of parameters to see if any improvement of our model is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.642Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [5, 10, 15], 'lr_all': [0.002, 0.005, 0.007],\n",
    "              'reg_all': [0.2, 0.4, 0.6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.649Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.655Z"
    }
   },
   "outputs": [],
   "source": [
    "svd_refined = SVD(n_epochs=15, lr_all=0.007, reg_all=0.2)\n",
    "_ = cross_validate(svd_refined, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our final solution we were able to give an individual recommendation of the top n routes for any individual user. This solves the problem as stated earlier.  \n",
    "\n",
    "Our final model uses `SVD` to produce recommendations based solely on user ratings. This approach was chosen as the previous attempt, using K-Means, failed to produce a significant cluster diversification (more than 99% of users were ended up in the same cluster). SVD has proven very useful in recommendation tasks, e.g. Netflix movie recommendation.  \n",
    "\n",
    "##### Assessing the robustness of our algorithm by comparing results of explicit vs implicit feedback.\n",
    "\n",
    "The SVD algorithm considers only __explicit feedback__. I.e. if a user gives a rating of one star, then this is counted as a one star rating. However, the __implicit feedback__ of a user is not considered. Implicit feedback means that a user, by chosing to rate a particular route he or she climbed (as opposed to not rating that route) already provides a positive indication for that route.\n",
    "\n",
    "The __SVD++__ algorithm can take that implicit feedback into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.704Z"
    }
   },
   "outputs": [],
   "source": [
    "svd_pp = SVDpp(n_epochs=15, lr_all=0.007, reg_all=0.2)\n",
    "_ = cross_validate(svd_pp, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.712Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "algos = ('Random recomm.', 'SVD', 'SVD++')\n",
    "y_pos = np.arange(len(algos))\n",
    "rmse = [1.1321, 0.6503, 0.6475]\n",
    "\n",
    "_ = plt.bar(y_pos, rmse, align='center', alpha=0.5)\n",
    "_ = plt.xticks(y_pos, algos)\n",
    "_ = plt.ylabel('RMSE')\n",
    "_ = plt.title('Comparing RMSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we can see that there is no significant difference between implicit and explicit feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison of our solution to the initial benchmark:\n",
    "\n",
    "|Model|Random model|SVD   |SVD tuned|\n",
    "|-----|:----------:|:----:|:-------:|\n",
    "|RMSE |1.1321      |0.6510|0.6489   |\n",
    "\n",
    "We can see a significant improvement of _RMSE_ from Random model over the SVD to the tuned SVD model (smaller RMSE is better), although the tuning did not gain much.\n",
    "\n",
    "Thus we have solved the problem of personalised recommendations for climbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free-Form Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of routes by climbing grade (= difficulty level of the route) to understand whether our climbers are mostly beginners, advanced or professionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.765Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = df_original.groupby('grade').count()['id'].plot(kind='bar', color='b', title='ascents by grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our distribution seems to have the general form of a bell shape, i.e. a Gaussian distribution. What seems odd though, are the two dents in the distribution at 6c and 7b.\n",
    "\n",
    "For this to understand we need to have some background knowledge on the different climbing grading systems used in different countries. The grading system used by 8a.nu, which is the source of our data set, is the _French_ grading system. In Germany a different grading system is used called _UIAA_.\n",
    "\n",
    "One peculiar thing about different grading systems is, that they do not follow the same step size. E.g. in French scale grading the step from one grade to the next higher grade could be smaller than the steps in between grades in UIAA. This can be seen when looking at a grade comparison chart as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/climbing_grades_comparison.png\" alt=\"Grade comparison table\" width=\"500\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the routes in Germany are given grades following UIAA scale. If a climber wants to log a climb in Germany with a UIAA grade on 8a.nu, he has to convert the grade to French scale. As there are no real corresponding entries for 6c and 7b in the UIAA scale, this explains the dent in our distribution.\n",
    "\n",
    "Therefore, joining the numbers from 6c and 6b+, as well as 7a+ and 7b seems reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-22T17:21:06.794Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grade_adjusted = df_original.copy()\n",
    "df_grade_adjusted.loc[df_grade_adjusted['grade'] == '6c'] = '6b+'\n",
    "df_grade_adjusted.loc[df_grade_adjusted['grade'] == '7b'] = '7a+'\n",
    "_ = df_grade_adjusted.groupby('grade').count()['id'].plot(\n",
    "    kind='bar', color='b', title='ascents by grade (adjusted)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-08T20:36:59.704039Z",
     "start_time": "2018-12-08T20:36:59.689393Z"
    }
   },
   "source": [
    "And the result of the distribution of logged climbs is now as expected.\n",
    "\n",
    "With the majority of climbs around 6c+, 7a level, what does this actually mean? Let's take a look at the assessment given by the website [thecrag.com](https://www.thecrag.com/en/article/grades#grade-ranges). And we can see that the majority of logged ascents are in the upper _Experienced_ range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/climbing_levels.png\" alt=\"Climbing levels\" width=\"500\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 419,
   "position": {
    "height": "514px",
    "left": "771px",
    "right": "20px",
    "top": "146px",
    "width": "559px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
